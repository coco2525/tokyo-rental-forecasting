# -*- coding: utf-8 -*-
"""data_processing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MDBGN2naodJCdqoXq71RaWdFYhm28x5c
"""

# Data Source: https://realestate.co.jp/en/rent
# Resource: https://github.com/ShoKosaka/Suumo/blob/master/Scraping.ipynb

from bs4 import BeautifulSoup
import requests
import pandas as pd
from pandas import Series, DataFrame
import time
import re

url = 'https://realestate.co.jp/en/rent/listing?prefecture=JP-13&trainline=25001&station=&min_price=&max_price=&min_meter=&rooms=&distance_station=&agent_id=&building_type=&building_age=&updated_within=&transaction_type=&order=&search=Search'

# Fetch data
page = requests.get(url)
soup = BeautifulSoup(page.content, 'html.parser')

# Get the number of pages
body = soup.find("body")
pages = body.find_all("li", class_="pagination-last")

# Check if there are any pages
if pages:
  last_page = pages[0].find("a")
  if last_page:
    href = last_page.get("href")
    # Split the href string to extract the page number and convert it to an integer
    page_number = int(href.split("page=")[-1])
    print("Last page number:", page_number)

# List to store URLs
urls = []

# Store the first page
urls.append(url)

# Store from the second page to the last page
for i in range(page_number - 1):
  pg = str(i + 2)
  url_page = url + '&page=' + pg
  urls.append(url_page)

# Display the URL list for confirmation
for url in urls:
  print(url)

# List initialization
room_type = []
category = []
street = []
city = []
prefecture = []
cost = []
size = []
deposit = []
key_money = []
floor = []
year = []
station = []
minute = []

# Scrape each URL
count = 0
for url in urls:
    result = requests.get(url)

    if result.status_code == 200:
        soup = BeautifulSoup(result.content, 'html.parser')
        summary = soup.find_all("div", class_="listing-body")

        if not summary:
            continue

        for i in range(len(summary)):
            # Get room_type and category
            name = summary[i].find("span", class_="text-semi-strong")
            if name:
                name_text = name.get_text(separator=" ", strip=True)
                room_type_part, category_part = name_text.split(' ', 1)
                room_type.append(room_type_part.strip())
                category.append(category_part.strip())
            else:
                room_type.append(None)
                category.append(None)

            # Get address
            address = summary[i].find("span", itemprop="address")
            if address:
                address_text = address.get_text(separator=", ", strip=True).replace('in ', '')
                try:
                    street_part, city_part, prefecture_part = address_text.split(', ')
                    street.append(street_part.strip())
                    city.append(city_part.strip())
                    prefecture.append(prefecture_part.strip())
                except ValueError as e:
                    print(f"Error processing address: {address_text}, Error: {e}")
                    street.append(None)
                    city.append(None)
                    prefecture.append(None)
            else:
                street.append(None)
                city.append(None)
                prefecture.append(None)

            # Get various property details
            found_floor = False
            found_station = False
            found_minute = False

            for x in summary[i].find_all("div", class_="listing-item"):
                text = x.get_text(strip=True)

                # Get cost
                if "Monthly Costs" in text:
                    cost_text = text.replace("Monthly Costs", "").replace("¥", "").replace(",", "").strip()
                    cost_value = re.findall(r'\d+', cost_text)
                    if cost_value:
                        cost.append(float(cost_value[0]))
                    else:
                        cost.append(None)

                # Get size
                if "Size" in text:
                    size_text = text.replace("Size", "").replace("m²", "").strip()
                    size.append(float(size_text))

                # Get deposit
                if "Deposit" in text:
                    deposit_text = text.replace("Deposit", "").replace("¥", "").replace(",", "").strip()
                    deposit.append(float(deposit_text))

                # Get key_money
                if "Key Money" in text:
                    key_money_text = text.replace("Key Money", "").replace("¥", "").replace(",", "").strip()
                    key_money.append(float(key_money_text))

                # Get floor
                if "Floor" in text:
                    floor_text = text.replace("Floor", "").replace("F", "").strip()
                    floor_number = re.findall(r'\d+', floor_text)
                    if floor_number:
                        floor.append(int(floor_number[0]))
                        found_floor = True

                # Get year
                if "Year Built" in text:
                    year_text = text.replace("Year Built", "").strip()
                    if year_text.isdigit():
                        year.append(int(year_text))
                    else:
                        year.append(None)

                # Get station and minute
                if "Nearest Station" in text:
                    nearest_station_text = text.replace("Nearest Station", "").strip()
                    if "(" in nearest_station_text and "min. walk)" in nearest_station_text:
                        try:
                            name_part, minute_part = nearest_station_text.split("(", 1)
                            name_text = name_part.replace(" Station", "").strip()
                            minute_text = minute_part.replace("min. walk)", "").strip()
                            station.append(name_text)
                            minute.append(int(minute_text))
                            found_station = True
                            found_minute = True
                        except ValueError as e:
                            print(f"Error processing nearest station text: {nearest_station_text}, Error: {e}")

            if not found_floor:
                floor.append(None)
            if not found_station:
                station.append(None)
            if not found_minute:
                minute.append(None)

        time.sleep(1)
        count += 1
        print(f"{count} pages completed / total {len(urls)} pages")
    else:
        print(f"Failed to retrieve page: {url}")

# Convert each list to a Series
room_type = Series(room_type)
category = Series(category)
street = Series(street)
city = Series(city)
prefecture = Series(prefecture)
cost = Series(cost)
size = Series(size)
deposit = Series(deposit)
key_money = Series(key_money)
floor = Series(floor)
year = Series(year)
station = Series(station)
minute = Series(minute)

# Concatenate each Series into a DataFrame
realestate_df = pd.concat([room_type, category, street, city, prefecture, cost, size, deposit, key_money, floor, year, station, minute], axis=1)

# Set column names
realestate_df.columns = ['room_type', 'category', 'street', 'city', 'prefecture', 'cost', 'size', 'deposit', 'key_money', 'floor', 'year', 'station', 'minute']

# Save as a CSV file with the specified file name
realestate_df.to_csv('Tokyo_Odakyu_Line_Rent_Buildings.csv', sep='\t', encoding='utf-8', index=False)